📝 Handwritten Text Extraction using LLaMA Vision Model
This project is a Flask-based web application that allows users to upload images containing handwritten text and automatically extracts the text using Unsloth's LLaMA 3.2 Vision-Instruct model.

🔍 Features
🔠 Extracts handwritten text from uploaded images

🧠 Powered by LLaMA 3.2 Vision-Instruct for high-quality image-to-text understanding

💻 Built with Flask and runs on CPU (no GPU required)

📁 Clean and simple interface for easy interaction

🚀 How It Works
The user uploads an image (JPG/PNG).

The image is processed and passed through the vision-language model.

The model responds with the extracted handwritten text.

The result is displayed to the user.

🛠️ Tech Stack
Python 🐍

Flask 🌐

PyTorch 🔥

PIL (Pillow) 🖼️
