ğŸ“ Handwritten Text Extraction using LLaMA Vision Model
This project is a Flask-based web application that allows users to upload images containing handwritten text and automatically extracts the text using Unsloth's LLaMA 3.2 Vision-Instruct model.

ğŸ” Features
ğŸ”  Extracts handwritten text from uploaded images

ğŸ§  Powered by LLaMA 3.2 Vision-Instruct for high-quality image-to-text understanding

ğŸ’» Built with Flask and runs on CPU (no GPU required)

ğŸ“ Clean and simple interface for easy interaction

ğŸš€ How It Works
The user uploads an image (JPG/PNG).

The image is processed and passed through the vision-language model.

The model responds with the extracted handwritten text.

The result is displayed to the user.

ğŸ› ï¸ Tech Stack
Python ğŸ

Flask ğŸŒ

PyTorch ğŸ”¥

PIL (Pillow) ğŸ–¼ï¸
